<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Qi Bi</title>

    <meta name="author" content="Qi Bi">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

   <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Qi Bi
                </p>
                <p>He is currently a lecturer jointly with the faculty of science and the Informatics Institute of <a href="https://www.uva.nl/">University of Amsterdam</a>.
                 Previous to that, he obtained his doctorate degree at the <a href="https://ivi.fnwi.uva.nl/cv/">Computer Vision Research Group</a> in <a href="https://www.uva.nl/">University of Amsterdam</a>, supervised by <a href="https://youshaodi.github.io/"> Dr. Shaodi You</a> and 
  <a href="https://staff.fnwi.uva.nl/th.gevers/"> Prof. Theo Gevers</a>.
                   His current research focus on robust vision in bad weather and domain generalization.
                </p>
               <p> Before that, He got his bachelor (BEng) and master degree (MSc) from <a href="https://en.whu.edu.cn/"> Wuhan University</a>
  in 2017 and 2020, supervised by Prof. Kun Qin and <a href="http://www.captain-whu.com/xia_En.html"> Prof. Gui-song Xia</a>,
  with a research focus on aerial image representation learning and multiple instance learning.
</p>
<p> In early 2020, He did research internship at the 
  <a href="https://jarvislab.tencent.com/index.html"> Jarvis Research Center, Tencent Youtu Lab</a>, led by 
  <a href="https://sites.google.com/site/yefengzheng"> Dr. Yefeng Zheng</a>, focusing on retinal image understanding.

</p> Email: q.bi[at]uva[dot]nl; q_bi[at]whu[dot]edu[dot]cn.
</p>
              
                <p style="text-align:center">
                  <a href="mailto:q.bi@uva.nl">Email</a> &nbsp;/&nbsp;
                  <a href="data/Qi Bi-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=v6RAqYwAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/BiQiWHU">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Qi Bi.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Qi Bi.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Honors and Awards</h2>
                 <p> Awarded as a <a href="https://neurips.cc/Conferences/2024/ProgramCommittee">top reviewer</a> for NeurIPS2024. </p>
                <p> Awarded as an <a href="https://bmvc2024.org/people/reviewers/">outstanding reviewer</a> for BMVC2024 (166/840). </p>
                <p> Awarded as an <a href="https://link.springer.com/journal/11263/updates/27620812">outstanding reviewer for International Journal of Computer Vision (IJCV)</a> in the year 2023. </p>
                <p> Awarded as an <a href="https://cvpr2023.thecvf.com/Conferences/2023/OutstandingReviewers">outstanding reviewer</a> for CVPR2023 (top 3.3%, 232/7403). </p>
<p> Work <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Learning_Calibrated_Medical_Image_Segmentation_via_Multi-Rater_Agreement_Modeling_CVPR_2021_paper.pdf"> multi-rater medical image segmentation</a> was shortlisted for 
  <a href="https://cvpr2021.thecvf.com/node/290"> CVPR2021 best paper candidate</a> (top 0.46%, 32/7015). 
   </p> 
<p> Work <a href="https://link.springer.com/chapter/10.1007/978-3-030-87237-3_6"> multi-instance medical image diagnosis</a> was shortlisted for <a href="https://www.miccai2021.org/en/MICCAI-2021-TRAVEL-AWARDS.html"> MICCAI2021 travel awards</a>.
</p>  
    Multiple journal publications on aerial scene representation learning have been indexed by Essential Science Indicators (ESI) as highly-cited papers.
</p>
<p> Awarded as National Excellent Graduate Students by Ministry of Education of the People's Republic of China in 2019. </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

</tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Professional Activities</h2>              
<p> 
  Regular reviewer for 
  <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34"> TPAMI</a>,
  <a href="https://www.springer.com/journal/11263"> IJCV</a>, 
  <a href="https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=83"> TIP</a>.
</p>
<p> 
  Regular reviewer for
  <a href="https://cvpr2022.thecvf.com/"> CVPR</a>,
  <a href="https://iccv2023.thecvf.com/"> ICCV</a>,
  <a href="https://eccv2022.ecva.net/"> ECCV</a>. 
</p>
<p> 
  Regular reviewer for
  <a href="https://nips.cc/virtual/2022/index.html"> NeurIPS</a>,
  <a href="https://icml.cc/Conferences/2024"> ICML</a>,
  <a href="https://iclr.cc/"> ICLR</a>.
</p>
<p> 
  Regular reviewer for
  <a href="https://aaai.org/aaai-conference/"> AAAI</a>,
  <a href="https://ijcai24.org/"> IJCAI</a>,
  <a href="https://2024.acmmm.org/"> ACM MM</a>. 
</p>

<p> IEEE member with <a href="https://signalprocessingsociety.org/"> Signal Processing Society</a>. </p>
<p> <a href="https://aaai.org/">AAAI</a> member. </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          
</tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                His research focuses on learning a universal and generalizable representation for visual intelligence, covering multiple application domains such as autonomous driving, medical imaging and aerial imaging. Some representative publications are listed below.
                </p>
                <p> 
                The research projects have not been updated for some time. For more recent works, please refer to <a href="https://scholar.google.com/citations?user=v6RAqYwAAAAJ&hl=en">Google Scholar</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/AAAI2024CMFormer.png' alt="" width="160" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/27840/27706">
                  <span class="papertitle">Learning Content-enhanced Mask Transformer for Domain Generalized Urban-scene Segmentation</span>
                </a>
                <br>
                <strong>Qi Bi</strong>, Shaodi You, Theo Gevers
                <br>
                <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</em>, 2024
                <br>
                <br>
                 <a href="https://github.com/BiQiWHU/CMFormer">code</a>
                <p></p>
                <p>Learning domain generalized scene segmentation by content-enhanced mask attention mechanism.</p>
              </td>
            </tr>
            
<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/AAAI2024fog.png' alt="" width="160" height="120">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/27838/27702">
                  <span class="papertitle">Learning Generalized Segmentation for Foggy-Scenes by Bi-directional Wavelet Guidance</span>
                </a>
                <br>
                <strong>Qi Bi</strong>, Shaodi You, Theo Gevers
                <br>
                <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</em>, 2024
                <br>
                <br>
                 <a href="https://github.com/BiQiWHU/BWG">code</a>
                <p></p>
                <p>Learning scene segmentation that can be generalized to arbitrary unseen foggy target domains from only a clear source domain; the first work for this task.</p>
              </td>
            </tr>

<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/AAAI2024DFQ.png' alt="" width="160" height="140">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/27839/27704">
                  <span class="papertitle">Learning Generalized Medical Image Segmentation from Decoupled Feature Queries</span>
                </a>
                <br>
                <strong>Qi Bi</strong>, Jingjun Yi, Hao Zheng, Wei Ji, Yawen Huang, Yuexiang Li, Yefeng Zheng
                <br>
                <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</em>, 2024
                <br>
                <br>
                 <a href="https://github.com/BiQiWHU/DFQ">code</a>
                <p></p>
                <p>Learning domain generalized medical image segmentation by querying from decoupled features; the first work to leverage Vision Transformer for domain generalized medical image segmentation.</p>
              </td>
            </tr>            
            
<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/TIP2023AD.png' alt="" width="160" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/10176286">
                  <span class="papertitle">
Interactive Learning of Intrinsic and Extrinsic Properties for All-day Semantic Segmentation</span>
                </a>
                <br>
                <strong>Qi Bi</strong>, Shaodi You, Theo Gevers
                <br>
                <em>IEEE Transactions on Image Processing (T-IP)</em>, 2023
                <br>
                <br>
                 <a href="https://github.com/BiQiWHU/All-day-CityScapes-segmentation">code</a>
                <br>
                <br>
                 <a href="https://isis-data.science.uva.nl/cv/1ADcityscape.zip">dataset</a>
                 <br>
                <p></p>
                <p>Learning robust scene semantic segmentation under all-day scenarios; proposing the first all-day semantic segmentation dataset All-day CityScapes.</p>
              </td>
            </tr>
        
<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/CVPRW2023SAM.png' alt="" width="160" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/pdf/2304.05750">
                  <span class="papertitle">Segment anything is not always perfect: An investigation of sam on different real-world applications</span>
                </a>
                <br>
                Wei Ji, Jingjing Li, <strong>Qi Bi</strong>, Wenbo Li, Li Cheng
                <br>
                <em>CVPR 1st workshop on Vision-based InduStrial InspectiON</em>, 2023
                <br>
                <br>
               <font color="red"><strong>Best paper award</strong></font>
                <br>
                <br>
                 <a href="https://github.com/LiuTingWed/SAM-Not-Perfect">code</a>
                <p></p>
                <p>Benchmarking Segment Anything (SAM) on multiple real-world scenarios.</p>
              </td>
            </tr>
       
<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/TGRS2022AGOS.png' alt="" width="160" height="140">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/9866803">
                  <span class="papertitle">All Grains, One Scheme (AGOS): Learning Multi-grain Instance Representation for Aerial Scene Classification</span>
                </a>
                <br>
                <strong>Qi Bi</strong>, Beichen Zhou, Kun Qin, Qinghao Ye, Gui-Song Xia
                <br>
                <em>IEEE Transactions on Geoscience and Remote Sensing (T-GRS)</em>, 2022
                <br>
                <br>
                <font color="red"><strong>ESI highly-cited paper</strong></font>
                <br>
                <br>
                 <a href="https://github.com/BiQiWHU/AGOS">code</a>
                <p></p>
                <p>Extending deep multiple instance learning into a multi-grain framework while maintaining the same semantic scheme, dubbed as AGOS; learning discriminative aerial scene representation by AGOS.</p>
              </td>
            </tr>
    
<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/AAAI2022Semi.png' alt="" width="160" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ojs.aaai.org/index.php/AAAI/article/download/20098/19857">
                  <span class="papertitle">Label-efficient Hybrid-supervised Learning for Medical Image Segmentation</span>
                </a>
                <br>
                Junwen Pan*, <strong>Qi Bi*</strong>, Yanzhan Yang, Pengfei Zhu, Cheng Bian 
                <br>
                <p></p>
                <br>
                * : equal contribution
                <br>
                <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</em>, 2022
                <br>
                <p></p>
                <p>Learning weakly semi-supervised medical image segmentation by the proposed dynamic instance indicator and dynamic co-regularization framework.</p>
              </td>
            </tr>

        
<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/TIP2021LSE.png' alt="" width="160" height="140">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/9477300">
                  <span class="papertitle">Local semantic enhanced convnet for aerial scene recognition</span>
                </a>
                <br>
                <strong>Qi Bi</strong>, Kun Qin, Han Zhang, Gui-Song Xia
                <br>
                <em>IEEE Transactions on Image Processing (T-IP)</em>, 2021
                <br>
                <br>
               <font color="red"><strong>ESI highly-cited paper</strong></font>
                <br>
                <br>
                 <a href="https://github.com/BiQiWHU/LSENet">code</a>
                <p></p>
                <p>Learning aerial scene representation by modeling context-aware class peak response.</p>
              </td>
            </tr>

<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/NIPS2021SOD.png' alt="" width="160" height="140">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/642e92efb79421734881b53e1e1b18b6-Paper.pdf">
                  <span class="papertitle">Joint semantic mining for weakly supervised RGB-D salient object detection</span>
                </a>
                <br>
                Jingjing Li, Wei Ji, <strong>Qi Bi</strong>, Cheng Yan, Miao Zhang, Yongri Piao, Huchuan Lu
                <br>
                <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2021
                <br>
                <br>
                <p></p>
                 <a href="https://github.com/jiwei0921/JSM">code</a>
                <p></p>
                 <a href="https://drive.google.com/file/d/1Oy9OGvQD2H7xrV9WH1j3n8xNS2UVT1cY/view?usp=sharing">dataset</a>
                <p></p>
                <p>Learning weakly-supervised RGB-D salient object detection (SOD) from the image, depth map and image caption; proposing a dataset for caption based SOD dubbed as CapS.</p>
              </td>
            </tr>

<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/MICCAI2021MIL.png' alt="" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://link.springer.com/chapter/10.1007/978-3-030-87237-3_6">
                  <span class="papertitle">Local-global dual perception based deep multiple instance learning for retinal disease classification</span>
                </a>
                <br>
                <strong>Qi Bi</strong>, Shuang Yu, Wei Ji, Cheng Bian, Lijun Gong, Hanruo Liu, Kai Ma, Yefeng Zheng
                <br>
                <em>Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>, 2021
                <br>
                 <br>
               <font color="red"><strong>MICCAI2021 travel awards</strong></font>
                <br>
                <br>
               <font color="red"><strong>MICCAI2021 young scientist award candidate</strong></font>
                <br>
                <p></p>
                <p>Learning retinal diseases from fundus images by local-global representation.</p>
              </td>
            </tr>

            
<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/MICCAI2021MILViT2.png' alt="" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://www.sciencedirect.com/science/article/pii/S1047320323002067">
                  <span class="papertitle">MIL-ViT: A multiple instance vision transformer for fundus image classification</span>
                </a>
                <br>
                <strong>Qi Bi</strong>, Xu Sun, Shuang Yu, Kai Ma, Cheng Bian, Munan Ning, Nanjun He, Yawen Huang, Yuexiang Li, Hanruo Liu, Yefeng Zheng
                <br>
                <em>Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>, 2021
                <br>
                <br>
                <br>
                 <a href="https://github.com/BiQiWHU/MIL-VT">code</a>
                <p></p>
                <p>Learning medical image Transformer by deep multiple instance learning.</p>
              </td>
            </tr>

            
<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/CVPR2021MultiRater.png' alt="" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="http://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Learning_Calibrated_Medical_Image_Segmentation_via_Multi-Rater_Agreement_Modeling_CVPR_2021_paper.pdf">
                  <span class="papertitle">Learning calibrated medical image segmentation via multi-rater agreement modeling</span>
                </a>
                <br>
                Wei Ji, Shuang Yu, Junde Wu, Kai Ma, Cheng Bian, <strong>Qi Bi</strong>, Jingjing Li, Hanruo Liu, Li Cheng, Yefeng Zheng
                <br>
                <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021
                <br>
                <br>
               <font color="red"><strong>Best paper candidate</strong></font>
                <br>
                <br>
                 <a href="https://github.com/jiwei0921/MRNet/">code</a>
                <p></p>
                <p>Learning medical image segmentation from multiple annotations by multi-rater modeling.</p>
              </td>
            </tr>

            
<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/TIP2020MIDC.png' alt="" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/9023551">
                  <span class="papertitle">A multiple-instance densely-connected ConvNet for aerial scene classification</span>
                </a>
                <br>
                <strong>Qi Bi</strong>, Kun Qin, Zhili Li, Han Zhang, Kai Xu, Gui-Song Xia
                <br>
                <em>IEEE Transactions on Image Processing (T-IP)</em>, 2020
                <br>
                <br>
               <font color="red"><strong>ESI highly-cited paper</strong></font>
                <br>
                <br>
                 <a href="https://github.com/BiQiWHU/Attention-based-Multi-instance-CNN">code</a>
                <p></p>
                <p>Modeling discriminative aerial scene representation by deep multiple instance learning.</p>
              </td>
            </tr>
            
</tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Supervision</h2>              
<p> Noud Corten, Improved Road Crack Severity Measurement Using Deep Convolutional Networks by Storing Spatial Information, November 2021-August 2022 (completed). </p>
<p> Carlo Airaghi, Multi-Stage Multiscale Training Architecture for Semantic Segmentation of Remote Sensing Images, April 2021- December 2021 (completed). </p>
<p> Silvan Murre, Layout2Land: Semi-Supervised Learning of a Layout and Style Reconfigurable GAN, March 2021-June 2021 (completed). </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
</tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Teaching</h2>   
<p> 2024 Vision & Autonomous Robotics (UvA, Lecturer) </p>
<p> 2024 Computer Vision 1 (UvA, Lecturer) </p>
<p> 2024 Computer Vision 2 (UvA, Teaching Assistant) </p>
<p> 2023 Computer Vision 1 (UvA, Teaching Assistant) </p>
<p> 2023 Computer Vision 2 (UvA, Teaching Assistant) </p>
<p> 2022 Computer Vision 1 (UvA, Teaching Assistant) </p>
<p> 2021 Computer Vision 1 (UvA, Teaching Assistant) </p>
<p> 2020 Computer Vision 1 (UvA, Teaching Assistant) </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

</tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                This website is based on Jon Barron's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
