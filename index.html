<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Qi Bi</title>

    <meta name="author" content="Qi Bi">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

   <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Qi Bi
                </p>
                <p>He is a fourth-year PhD student at the <a href="https://ivi.fnwi.uva.nl/cv/">Computer Vision Research Group</a> in <a href="https://www.uva.nl/">University of Amsterdam</a>, supervised by <a href="https://youshaodi.github.io/"> Dr. Shaodi You</a> and 
  <a href="https://staff.fnwi.uva.nl/th.gevers/"> Prof. Theo Gevers</a>.
                   His current research focus on robust vision in bad weather and domain generalization.
                </p>
               <p> Before that, He got his bacholar (BEng) and master degree (MSc) from <a href="https://en.whu.edu.cn/"> Wuhan University</a>
  in 2017 and 2020, supervised by Prof. Kun Qin and <a href="http://www.captain-whu.com/xia_En.html"> Prof. Gui-song Xia</a>,
  with a research focus on aerial image representation learning and multiple instance learning.
</p>
<p> In early 2020, He did research internship at the 
  <a href="https://jarvislab.tencent.com/index.html"> Jarvis Research Center, Tencent Youtu Lab</a>, led by 
  <a href="https://sites.google.com/site/yefengzheng"> Dr. Yefeng Zheng</a>, focusing on retinal image understanding.
</p> He has published about 30 peer-reviewed journal and conference papers in the past five years, with a citation of 1034, h-index of 17 and i10-index of 18 (By Jan. 2024).
</p>
              
                <p style="text-align:center">
                  <a href="mailto:q.bi@uva.nl">Email</a> &nbsp;/&nbsp;
                  <a href="data/Qi Bi-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=v6RAqYwAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/BiQiWHU">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Qi Bi.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Qi Bi.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Honors and Awards</h2>
                <p> He was awarded as an <a href="https://cvpr2023.thecvf.com/Conferences/2023/OutstandingReviewers">outstanding reviewer</a> for CVPR2023 (top 3.3%, 232/7403). </p>
<p> His work <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Learning_Calibrated_Medical_Image_Segmentation_via_Multi-Rater_Agreement_Modeling_CVPR_2021_paper.pdf"> multi-rater medical image segmentation</a> was shortlisted for 
  <a href="https://cvpr2021.thecvf.com/node/290"> CVPR2021 best paper candidate</a> (top 0.46%, 32/7015). 
   </p> 
<p> His work <a href="https://link.springer.com/chapter/10.1007/978-3-030-87237-3_6"> multi-instance medical image diagnosis</a> was shortlisted for <a href="https://www.miccai2021.org/en/MICCAI-2021-TRAVEL-AWARDS.html"> MICCAI2021 travel awards</a>.
</p>  
    His multiple journal publications on aerial scene representation learning have been indexed by Essential Science Indicators (ESI) as highly-cited papers.
</p>
<p> He was awarded as National Excellent Graduate Students by Ministry of Education of the People's Republic of China in 2019. </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

</tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Professional Activities</h2>              
<p> 
  He serves as a regular reviewer for 
  <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34"> TPAMI</a>,
  <a href="https://www.springer.com/journal/11263"> IJCV</a>, 
  <a href="https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=83"> TIP</a>.
</p>
<p> 
  He serves as a regular reviewer for
  <a href="https://cvpr2022.thecvf.com/"> CVPR</a>,
  <a href="https://iccv2023.thecvf.com/"> ICCV</a>,
  <a href="https://eccv2022.ecva.net/"> ECCV</a>. 
</p>
<p> 
  He serves as a regular reviewer for
  <a href="https://nips.cc/virtual/2022/index.html"> NeurIPS</a>,
  <a href="https://icml.cc/Conferences/2024"> ICML</a>,
  <a href="https://iclr.cc/"> ICLR</a>. 
</p>
<p> 
  He serves as a regular reviewer for
  <a href="https://aaai.org/aaai-conference/"> AAAI</a>,
  <a href="https://ijcai24.org/"> IJCAI</a>,
  <a href="https://2023.emnlp.org/"> EMNLP</a>,
  <a href="https://conferences.miccai.org/2022/en/"> MICCAI</a>. 
</p>

<p> He is an IEEE student member with <a href="https://signalprocessingsociety.org/"> Signal Processing Society</a>. </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          
</tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                 Some selected publications are summarized as follows.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/MICCAI2021MIL.png' alt="" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://link.springer.com/chapter/10.1007/978-3-030-87237-3_6">
                  <span class="papertitle">Local-global dual perception based deep multiple instance learning for retinal disease classification</span>
                </a>
                <br>
                <strong>Qi Bi</strong>, Shuang Yu, Wei Ji, Cheng Bian, Lijun Gong, Hanruo Liu, Kai Ma, Yefeng Zheng
                <br>
                <em>Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>, 2021
                <br>
                <br>
                 <br>
               <font color="red"><strong>MICCAI2021 travel awards</strong></font>
                <br>
                <p></p>
                <p>Learning retinal diseases from fundus images by local-global representation.</p>
              </td>
            </tr>

            
<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/MICCAI2021MILViT2.png' alt="" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://www.sciencedirect.com/science/article/pii/S1047320323002067">
                  <span class="papertitle">MIL-ViT: A multiple instance vision transformer for fundus image classification</span>
                </a>
                <br>
                <strong>Qi Bi</strong>, Xu Sun, Shuang Yu, Kai Ma, Cheng Bian, Munan Ning, Nanjun He, Yawen Huang, Yuexiang Li, Hanruo Liu, Yefeng Zheng
                <br>
                <em>Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>, 2021, conference version
                <br>
                <em>Journal of Visual Communication and Image Representation</em>, 2023, journal version
                <br>
                <br>
                 <a href="https://github.com/BiQiWHU/MIL-VT">code</a>
                <p></p>
                <p>Learning medical image Transformer by deep multiple instance learning.</p>
              </td>
            </tr>

            
<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/CVPR2021MultiRater.png' alt="" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="http://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Learning_Calibrated_Medical_Image_Segmentation_via_Multi-Rater_Agreement_Modeling_CVPR_2021_paper.pdf">
                  <span class="papertitle">Learning calibrated medical image segmentation via multi-rater agreement modeling</span>
                </a>
                <br>
                Wei Ji, Shuang Yu, Junde Wu, Kai Ma, Cheng Bian, <strong>Qi Bi</strong>, Jingjing Li, Hanruo Liu, Li Cheng, Yefeng Zheng
                <br>
                <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021
                <br>
                <br>
               <font color="red"><strong>Best paper candidate</strong></font>
                <br>
                <br>
                 <a href="https://github.com/jiwei0921/MRNet/">code</a>
                <p></p>
                <p>Learning medical image segmentation from multiple annotations by multi-rater modeling.</p>
              </td>
            </tr>

            
<tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/TIP2020MIDC.png' alt="" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/9023551">
                  <span class="papertitle">A multiple-instance densely-connected ConvNet for aerial scene classification</span>
                </a>
                <br>
                <strong>Qi Bi</strong>, Kun Qin, Zhili Li, Han Zhang, Kai Xu, Gui-Song Xia
                <br>
                <em>IEEE Transactions on Image Processing (T-IP)</em>, 2020
                <br>
                <br>
               <font color="red"><strong>ESI highly-cited paper</strong></font>
                <br>
                <br>
                 <a href="https://github.com/BiQiWHU/Attention-based-Multi-instance-CNN">code</a>
                <p></p>
                <p>Modeling discriminative aerial scene representation by deep multiple instance learning.</p>
              </td>
            </tr>
            
</tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Supervision</h2>              
<p> Noud Corten, Improved Road Crack Severity Measurement Using Deep Convolutional Networks by Storing Spatial Information, November 2021-August 2022 (completed). </p>
<p> Carlo Airaghi, Multi-Stage Multiscale Training Architecture for Segmantic Segmentation of Remote Sensing Images, April 2021- December 2021 (completed). </p>
<p> Silvan Murre, Layout2Land: Semi-Supervised Learning of a Layout and Style Reconfigurable GAN, March 2021-June 2021 (completed). </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
</tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Teaching</h2>              
<p> 2023 Computer Vision 1 (UvA, Teaching Assistant) </p>
<p> 2023 Computer Vision 2 (UvA, Teaching Assistant) </p>
<p> 2022 Computer Vision 1 (UvA, Teaching Assistant) </p>
<p> 2021 Computer Vision 1 (UvA, Teaching Assistant) </p>
<p> 2020 Computer Vision 1 (UvA, Teaching Assistant) </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

